{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395eeab1-3e22-4ede-89e7-d599d57c4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your Python Libraries here\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cbdd91-8587-40c7-8429-bb7e790907a2",
   "metadata": {},
   "source": [
    "***\n",
    "# Add Python function below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644daaf6-bab9-4ba4-98a2-9c7b360b1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gridded_data(filename, report=True):\n",
    "    \"\"\" function to read regular gridded data files and return a Python dictionary.\n",
    "    inputs: filename -> name of file to be read\n",
    "            report   -> boolean flag, if true then a table listing the file contents is printed to screen\n",
    "\n",
    "    outputs: data    -> a python dictionary containing the file contents\n",
    "    \"\"\"\n",
    "    # open the file and map the contents to a netCDF object. Use a test to capture\n",
    "    # any issues with the data file\n",
    "    try:\n",
    "        nc = netCDF4.Dataset(filename,\"r\")\n",
    "    except IOError:\n",
    "        raise\n",
    "    # if report is set to true then prind global attributes\n",
    "    if report == True:\n",
    "        print(f\"Global Attributes For File: {filename}\") # when witing strings, starting them with an 'f' allows you to insert other variables using {}.\n",
    "        print(\"----------------------------------------------------------------------------------------------------\")\n",
    "        print(nc)\n",
    "    # Define a dictionary to hold the contents\n",
    "    data = {} \n",
    "    # loop over the file contents and write\n",
    "    if report == True:\n",
    "        # what variables are in this file?\n",
    "        # printing Aligned Header \n",
    "        print(\"-------------------------------------------------------------------\")        \n",
    "        print(f\"{'Variable Name' : <14} |{'Long Name':<32} |{'tdim, ydim, xdim':>17}\") \n",
    "        print(\"-------------------------------------------------------------------\")\n",
    "    else:\n",
    "        pass # we add a pass so we can close this if statement with an else\n",
    "\n",
    "    for varname in nc.variables.keys():\n",
    "        if report == True:\n",
    "            print(f\"{varname:<14} |{nc[varname].long_name:<32} |{', '.join([str(d) for d in nc[varname].shape]):>17}\")\n",
    "        else:\n",
    "            pass\n",
    "        # write the variable to the dictionary\n",
    "        data[varname] = nc[varname][:] #  the [:] at the end indexes all the data\n",
    "    \n",
    "    # finally close the file\n",
    "    nc.close()\n",
    "\n",
    "    # return the filled data dictionary\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a867f0-8a80-48c8-a284-2ba0467d10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_moving_average(yvals, width):\n",
    "    \"\"\" compute the moving average of a time series with a user defined sliding window.\n",
    "    inputs: yvals -> time series on regular time steps\n",
    "            width -> width of sliding window (n time steps)\n",
    "    output: sommothed time series\n",
    "    \"\"\"\n",
    "    return np.convolve(yvals, np.ones(width), 'same')/width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bbebe4-e702-4a88-8f52-509e289aaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probDensFunc(yvals, ymin, ymax,nbins=100):\n",
    "    \"\"\" calculate a PDF from the array yvals using scipy.stats norm module\n",
    "    inputs: yvals -> 1d array of values to be used in PDF calculation\n",
    "            ymin  -> minimum value for range of yvals PDF is calculated\n",
    "            ymax  -> maximum value for range of yvals PDF is calculated\n",
    "            nbins -> number of bins for which PDF is calculated between ymin  and ymax\n",
    "            \n",
    "    outputs: xvals -> array of values over which the PDF was calculated (defined by ymin, ymax,nbins)\n",
    "             PDF   -> array containing PDF values\n",
    "    \"\"\"\n",
    "    # define xvals\n",
    "    xvals = np.linspace(ymin,ymax,nbins)\n",
    "\n",
    "    # calculate mean and standard deviation of yvals\n",
    "    mu = np.mean(yvals)\n",
    "    std = np.std(yvals)\n",
    "\n",
    "    # define an empty array to hold PDF values. Here we use the size method to tell the code how many elements \n",
    "    # are in this new array and fill each entry with a default value NaN (Not a Number)\n",
    "    PDF = np.full(xvals.size, np.nan)\n",
    "\n",
    "    # loop over each value in x and calculate the corresponding PDF value. Because xvals is an array merans in \n",
    "    # Python it is iterable (i.e. we can loop over the contents) and by wrapping it in the enumerate function\n",
    "    # we also get the index of the value (e.g. the firts value in xvals could be -2, therefore x=-2 and ii=0).\n",
    "    for ii, x in enumerate(xvals):\n",
    "        PDF[ii] = norm.pdf(x, loc=mu, scale=std)\n",
    "\n",
    "    # return the results\n",
    "    return PDF, xvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a228c14-3c8d-4f9d-8263-252ae850d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_coef(x, y):\n",
    "    \"\"\" python implimentation of linear regression.\n",
    "    Inputs: x -> 1D array (e.g. fractional year)\n",
    "            y -> 1D array (e.g. UTH anomaly)\n",
    "\n",
    "    Outputs: coeffs -> tuple containing the intercept and gradient\n",
    "    \"\"\"\n",
    "    # define number of observations/points\n",
    "    n = np.size(x)\n",
    "    \n",
    "    # calculate the mean of the x and y vectors\n",
    "    m_x = np.mean(x)\n",
    "    m_y = np.mean(y)\n",
    "    \n",
    "    # calculate cross-deviation and deviation about x\n",
    "    SS_xy = np.sum(y*x) - n*m_y*m_x\n",
    "    SS_xx = np.sum(x*x) - n*m_x*m_x\n",
    "    \n",
    "    # calculate regression coefficients\n",
    "    b_1 = SS_xy / SS_xx\n",
    "    b_0 = m_y - b_1*m_x\n",
    "    \n",
    "    return (b_0, b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294232e-7085-47ee-95ba-5d66cf785427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "705d6ee4-54f3-4d51-946a-ad318fe168d5",
   "metadata": {},
   "source": [
    "***\n",
    "# Add your workflow under here, think of it as a set of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56b1c8-5eee-4238-aea5-8874ccd7650a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
